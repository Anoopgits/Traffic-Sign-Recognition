# -*- coding: utf-8 -*-
"""Traffic Signs Recognition.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1s59I4bcVoO9CYEE1GK4cNgz_-CJyP0ZX
"""

! pip install opendatasets

import opendatasets as od
od.download("https://www.kaggle.com/datasets/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign",force=True )

"""import all required library"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os
import warnings
warnings.filterwarnings('ignore')
import cv2
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

"""Step 2: Load Dataset Paths"""

data_dir = "/content/gtsrb-german-traffic-sign"
train_csv = os.path.join(data_dir, "Train.csv")
train_df = pd.read_csv(train_csv)

print("Sample data:")
print(train_df.head())

image_dir = os.path.join(data_dir, "Train")

"""Step 3: Load and Preprocess Images"""

import os
import cv2
import numpy as np
import pandas as pd
from tensorflow.keras.utils import to_categorical

img_size = 32
images = []
labels = []

# Print the first few paths from the DataFrame to inspect their format
print("Sample paths from train_df['Path']:")
print(train_df['Path'].head())

for i, row in train_df.iterrows():
    # Construct the full image path
    img_path = os.path.join(data_dir, row['Path']) # Join data_dir instead of image_dir
    print(f"Attempting to load: {img_path}") # Print the path being attempted
    img = cv2.imread(img_path, cv2.IMREAD_COLOR)  # Ensures 3 channels
    if img is not None:
        img = cv2.resize(img, (img_size, img_size))
        images.append(img)
        labels.append(int(row['ClassId']))
    else:
        # Print a more specific warning if the file doesn't exist
        if not os.path.exists(img_path):
            print(f"Error: File not found at path: {img_path}")
        else:
            print(f"Warning: Could not load image at path (unknown error): {img_path}")


if not images:
    print("No images were loaded. Check paths and file existence.")
else:
    X = np.array(images)
    y = to_categorical(np.array(labels))
    print(f"Successfully loaded {len(images)} images.")
    print(f"Shape of X: {X.shape}")
    print(f"Shape of y: {y.shape}")

plt.imshow(X[0])
plt.title(f"Label: {np.argmax(y[0])}")  # shows the class label
plt.axis('off')
plt.show()

for i in range(5):
    plt.subplot(1, 5, i+1)
    plt.imshow(X[i])
    plt.title(np.argmax(y[i]))
    plt.axis('off')

plt.tight_layout()
plt.show()

plt.imshow((X[0] * 255).astype(np.uint8))

"""Split the dataset in train test dataset"""

x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)

x_train.shape

x_test.shape

"""Model design

"""

model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)),
    MaxPooling2D(2,2),
    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),
    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(y.shape[1], activation='softmax')
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

model.summary()

"""Train the model"""

history=model.fit(x_train, y_train, epochs=10, validation_data=(x_test,y_test), batch_size=64)

"""to plot this accuracy and val accuracy"""

import matplotlib.pyplot as plt
plt.plot(history.history['accuracy'])
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()

import matplotlib.pyplot as plt

# Accuracy plot
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Val Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)
plt.show()

# Loss plot
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)
plt.show()

"""Hyperparameter tuning"""

filter_sets = [(32, 64), (64, 128)]
dense_units = [128, 256]
dropouts = [0.3, 0.5]
learning_rates = [0.001, 0.0005]
batch_sizes = [64]

results = []

for filters in filter_sets:
    for dense in dense_units:
        for dropout in dropouts:
            for lr in learning_rates:
                for batch in batch_sizes:

                    print(f"\nTraining model: Filters={filters}, Dense={dense}, Dropout={dropout}, LR={lr}, Batch={batch}")

                    model = Sequential([
                        Conv2D(filters[0], (3,3), activation='relu', input_shape=(32,32,3)),
                        MaxPooling2D(2,2),
                        Conv2D(filters[1], (3,3), activation='relu'),
                        MaxPooling2D(2,2),
                        Flatten(),
                        Dense(dense, activation='relu'),
                        Dropout(dropout),
                        Dense(43, activation='softmax')
                    ])

                    optimizer = Adam(learning_rate=lr)
                    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])

                    history = model.fit(x_train, y_train, epochs=5, batch_size=batch, verbose=0,
                                        validation_data=(x_test, y_test))

                    val_acc = history.history['val_accuracy'][-1]
                    train_acc = history.history['accuracy'][-1]

                    print(f"â†’ Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}")

                    results.append({
                        'filters': filters,
                        'dense': dense,
                        'dropout': dropout,
                        'lr': lr,
                        'batch_size': batch,
                        'val_accuracy': val_acc,
                        'train_accuracy': train_acc
                    })

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.optimizers import Adam

model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)),
    MaxPooling2D(2,2),

    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),

    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.3),
    Dense(43, activation='softmax')  # 43 classes
])

optimizer = Adam(learning_rate=0.001)
model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])

history=model.fit(x_train, y_train, epochs=15, validation_data=(x_test,y_test), batch_size=64)

import matplotlib.pyplot as plt

# Accuracy plot
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Val Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)
plt.show()

# Loss plot
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)
plt.show()

model.save("traffic_sign_model.h5")

